---
title: "Exámen Interciclo - Inteligencia Artificial"
format: pdf
editor: visual
author: Daniela Cuesta 
---

```{r}
library(ggplot2)
library(dplyr)
library(caret)
library(e1071)
library(ggstatsplot)
library(psych)
```

## [**Descripción del conjunto de datos.**]{.underline}

```{r}
datos <- read.csv("./datos/cancer.csv")
```

```{r}
str(datos)

```

1.  [***Realizar una estadística descriptiva numérica de los datos***]{.underline}

```{r}
summary(datos)  # Resumen estadístico básico
```

**Interpretación**

Cuando se aplica **`summary()`** a un conjunto de datos, se calculan varias estadísticas descriptivas para cada columna. Estas estadísticas pueden incluir:

Para variables numéricas:

-   Mínimo (valor mínimo)

-   Cuartil 1 (Q1, el valor que divide el conjunto de datos en el 25% inferior)

-   Mediana (Q2, el valor que divide el conjunto de datos en el 50%)

-   Media (promedio aritmético)

-   Cuartil 3 (Q3, el valor que divide el conjunto de datos en el 75% inferior)

-   Máximo (valor máximo)

2.  [***Realizar estadística descritptiva univariante inferencial para las 10 primeras columnas. Podéis hacer uso del paquete ggstatsplot::ggbetweenstats respecto a la categoría de diagnóstico***]{.underline}

```{r}
columnas2a11 <-c("mean_radius", "mean_texture", "mean_perimeter", "mean_area", "mean_smoothnes", "mean_compactness", "mean_concavity", "mean_concave_points", "mean_simmetry", "mean_fractal_dimension")
for (ccol in columnas2a11){
  simbolo <-as.name(ccol)#col representa el nombre de una columna en columnas2a11. Al utilizar as.name(ccol), se convierte el valor de col (que es una cadena de caracteres) en un símbolo. !!col_sym usarlo como un identificador de columna en la función ggbetweenstats.
  plot <- ggbetweenstats(data = datos, x = diagnostico, y = !!simbolo, type="np")
  print(plot)
}

```

**Interpretación**

Dentro de la interpretaciones que se van a realizar hay que tener claro que el número de tumores benignos incluidos en el análisis es mayor (n = 357) en comparación con el número de tumores malignos (n = 212). Además que en cada interpretacion la mediana cambia tanto para los tumores benignos como malignos.

Estas diferencias en las medianas podrían indicar una posible relación entre todas las características del tumor y la naturaleza benigna o maligna del mismo.

**Mean_radius**

El gráfico sugieren que, en promedio, los tumores benignos tienen un tamaño de radio medio menor (mediana de 12.20) en comparación con los tumores malignos (mediana de 17.33).

**Mean_Texture**

El gráfico sugieren que, en promedio, los tumores benignos tienen una textura media menor (mediana de 17.39) en comparación con los tumores malignos (mediana de 21.46).

**Mean_Perimeter**

El gráfico sugiere que, en promedio, los tumores benignos tienen un perímetro medio menor (mediana de 78.18) en comparación con los tumores malignos (mediana de 114.20).

**Mean_Area**

El gráfico sugiere que, en promedio, los tumores benignos tienen un área media menor (mediana de 458.40) en comparación con los tumores malignos (mediana de 932.00).

**Mean_Smoothness**

El gráfico indica que, en promedio, los tumores malignos tienen una suavidad media ligeramente mayor (mediana de 0.10) en comparación con los tumores benignos (mediana de 0.09).

**Mean_Compactness**

El gráfico indica que, en promedio, los tumores malignos tienen una compacidad media mayor (mediana de 0.13) en comparación con los tumores benignos (mediana de 0.06).

La compacidad de los tumores puede ser un factor relevante para distinguir entre tumores benignos y malignos.

**Mean_Concavity**

El gráfico indica que, en promedio, los tumores malignos tienen una concavidad media mayor (mediana de 0.15) en comparación con los tumores benignos (mediana de 0.04).

La concavidad de los tumores puede ser un factor relevante para distinguir entre tumores benignos y malignos.

**Mean_Concave_Points**

El gráfico indica que, en promedio, los tumores malignos tienen una mayor cantidad de puntos cóncavos medios (mediana de 0.09) en comparación con los tumores benignos (mediana de 0.02).

La presencia y cantidad de puntos cóncavos pueden ser características importantes para distinguir entre tumores benignos y malignos.

**Mean_Simmetry**

El gráfico indica que, en promedio, los tumores malignos tienen una simetría media ligeramente mayor (mediana de 0.19) en comparación con los tumores benignos (mediana de 0.17).

La simetría de los tumores puede ser una característica importante para distinguir entre tumores benignos y malignos.

**Mean_Fractal_Dimension**

El gráfico indica que la mediana de la dimensión fractal media es similar tanto para los tumores benignos como para los tumores malignos (ambos con una mediana de 0.06).

La dimensión fractal puede ser una medida interesante para caracterizar los tumores, pero en este caso particular no parece haber una diferencia significativa entre los tumores benignos y malignos en términos de su dimensión fractal media.

3.  [**Realizar un gráfico de correlaciones**]{.underline}

```{r}

# Filtrar las columnas relevantes en un nuevo data frame
datos_seleccionados <- datos[columnas2a11]

# Calcular la matriz de correlación y los valores p
obj.cor <- psych::corr.test(datos_seleccionados)
p.values <- obj.cor$p
p.values[upper.tri(p.values)] <- obj.cor$p.adj
p.values[lower.tri(p.values)] <- obj.cor$p.adj
diag(p.values) <- 1

# Visualizar el gráfico de correlaciones utilizando la función corrplot
corrplot::corrplot(corr = obj.cor$r, p.mat = p.values, sig.level = 0.05, insig = "label_sig")

```

-   **Matriz de correlación**

    Los valores de correlación varían entre -1 y 1. Un valor de 1 indica una correlación positiva perfecta, -1 indica una correlación negativa perfecta y 0 indica una ausencia de correlación.

-   **Valores p:**

    Indican si la correlación observada entre dos variables es estadísticamente significativa. Los valores p más bajos indican una mayor significancia estadística.

-   **Gráfico de correlaciones:**

    El gráfico de correlaciones visualiza la matriz de correlación utilizando colores y símbolos.

    Las correlaciones positivas están representadas en tonos de azul, mientras que las correlaciones negativas están representadas en tonos de rojo.

    El color y la intensidad del cuadro indican la fuerza de la correlación. Tonos más intensos representan correlaciones positivas fuertes, mientras que tonos más claros representan correlaciones positivas más débiles.

-   Las correlaciones negativas se representan en tonos de rojo.

-   Los asteriscos (\*) en las celdas indican la significancia estadística de las correlaciones. Los asteriscos más grandes indican una significancia estadística más fuerte.

Si la celda está vacía, indica que la correlación no es estadísticamente significativa.

**Interpretación**

Según el análisis del gráfico de correlaciones se puede observar que la correlacion de mean_radius con mean_perimeter, y la correlacion entre mean_radius y mean_area es una correlación perfecta ya que su valor de p es bajo, esto quiere decir que tienen mayor significancia estadística

4.  [***Realizar un PCA sobre las 10 primeras variables. Debe de contener: Scree plot y Biplot***]{.underline}

```{r}

# Calcular el PCA
pcx <- prcomp(datos_seleccionados, scale. = FALSE)

# Scree plot
scree <- pcx$sdev^2 / sum(pcx$sdev^2)
plot(1:length(scree), scree, type = "b", xlab = "Componentes", ylab = "Proporción de Varianza Explicada", 
     main = "Scree Plot", col = "blue", pch = 19)

# Biplot
biplot(pcx, scale = 0, col = c("blue", "red"), cex = 0.7, main = "Biplot - PCA")

# Ajustar las etiquetas de los puntos
text(pcx$rotation[, 1], pcx$rotation[, 2], labels = colnames(datos_seleccionados), cex = 0.7, pos = 4)

# Añadir líneas de referencia para los ejes
abline(h = 0, v = 0, lty = 2)
```

**Interpretación**

-   **Scree Plot:**

    El Scree Plot muestra la proporción de varianza. Cada punto en el gráfico representa un componente principal, y en el eje y se muestra la proporción de varianza explicada. El eje x indica el número de componentes.

    En el Scree Plot, la línea trazada conectando los puntos muestra cómo se acumula la varianza explicada a medida que se agregan más componentes principales.

    El punto de inflexión en el gráfico, donde la curva se aplana o se desacelera, suele indicar el número óptimo de componentes principales a retener. Los componentes anteriores a este punto suelen explicar la mayor parte de la variabilidad en los datos, mientras que los componentes posteriores pueden contener información menos relevante o ruido.

-   **Biplot:**

    El gráfico Biplot del PCA muestra la representación de los componentes principales en un espacio bidimensional, donde cada punto representa una variable original (en este caso, las columnas seleccionadas del conjunto de datos).

    El color de los puntos en el Biplot se utiliza para representar el diagnóstico de los casos (categoría "benigno" o "maligno").

    Las líneas de referencia que intersectan en el origen (punto \[0,0\]) representan los ejes de los componentes principales. Estas líneas proporcionan una referencia para la dirección y la orientación de las variables y las observaciones en el espacio del PCA.

## [**Realizar una predicción del diagnóstico con Naive Bayes mediante el paquete e1071 (20 %)**]{.underline}

[**1. Dividir el conjunto de datos en prueba y entrenamiento con la semilla de aleatorizaciónset.seed(123456)**]{.underline}

```{r}
set.seed(123456)  # Semilla de aleatorización

# Dividir el conjunto de datos en entrenamiento y prueba
train_indices <- sample(1:nrow(datos), nrow(datos)*0.7)  # 70% de los datos para entrenamiento
train_data <- datos[train_indices, ]
test_data <- datos[-train_indices, ]
```

[**2. Entrenar y realizar la predicción del diagnóstico**]{.underline}

```{r}
# Definir la fórmula para el modelo Naive Bayes
formula <- as.formula(paste("diagnostico ~", paste(columnas2a11, collapse = "+")))

# Entrenar el modelo Naive Bayes
model <- naiveBayes(formula, data = train_data)

# Realizar la predicción en el conjunto de prueba
predictions <- predict(model, test_data)
```

[**3. Obtener la matriz de confusión. Obtener Accuracy, Specificity y Sensibility**]{.underline}

```{r}
# Obtener la matriz de confusión
confusion <- table(test_data$diagnostico, predictions)
print(confusion)

# Calcular Accuracy, Specificity y Sensibility
accuracy <- sum(diag(confusion)) / sum(confusion)
specificity <- confusion["B", "B"] / sum(confusion[, "B"])
sensitivity <- confusion["M", "M"] / sum(confusion[, "M"])

# Imprimir los resultados
print(paste("Accuracy:", accuracy))
print(paste("Specificity:", specificity))
print(paste("Sensitivity:", sensitivity))
```

**Interpretación**

La matriz de confusión muestra las predicciones realizadas por el modelo. En este caso, hay 101 casos clasificados correctamente como "B" (benigno) y 53 casos clasificados correctamente como "M" (maligno). También hay 8 casos clasificados erróneamente como "M" cuando eran "B" y 9 casos clasificados erróneamente como "B" cuando eran "M", es decir se confundieron entre si eran malignos o beningnos

-   Accuracy (Precisión): La precisión es una medida que indica qué tan bien el modelo predice correctamente todas las clases. En este caso, el modelo tiene una precisión del 90.06%.

-   Specificity (Especificidad): La especificidad es una medida que indica cuántas instancias benignas son clasificadas correctamente. En este caso, el modelo clasifica correctamente el 91.82% de los casos benignos.

-   Sensitivity (Sensibilidad o Tasa de Verdaderos Positivos): La sensibilidad es una medida que indica cuántas instancias malignas son clasificadas correctamente. En este caso, el modelo clasifica correctamente el 86.89% de los casos malignos.

Estos valores indican el rendimiento del modelo en términos de clasificar correctamente los casos en cada clase y pueden ser utilizados para evaluar su eficacia en la detección de casos malignos y benignos.

## [Realizar una extracción de las características más importantes]{.underline}

[**Realizar una regresión logística regularizada de LASSO**]{.underline}

```{r}
# Definir la cuadrícula de hiperparámetros para búsqueda
tuneGrid <- expand.grid(.alpha = 1, .lambda = seq(0, 1, by = 0.001))

# Definir el control de entrenamiento
trainControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3, classProbs = TRUE)
```

[**2. Entrenar y predecir el diagnóstico**]{.underline}

```{r}
# Ajustar el modelo de regresión logística con LASSO
model <- train(diagnostico ~ ., data = train_data, method = "glmnet", trControl = trainControl, tuneGrid = tuneGrid, metric = "Accuracy")

# Realizar predicciones en el conjunto de prueba
predictions <- predict(model, test_data)
```

[**3. Obtener la matriz de confusión, Obtener Accuracy, Specificity y Sensibility**]{.underline}

```{r}
# Crear la matriz de confusión
confusion <- table(Actual = test_data$diagnostico, Predicted = predictions)

# Calcular Accuracy, Specificity y Sensitivity
accuracy <- sum(diag(confusion)) / sum(confusion)
specificity <- confusion["B", "B"] / sum(confusion[, "B"])
sensitivity <- confusion["M", "M"] / sum(confusion[, "M"])

# Imprimir la matriz de confusión
print("Matriz de Confusión:")
print(confusion)

# Imprimir los resultados
print(paste("Accuracy:", accuracy))
print(paste("Specificity:", specificity))
print(paste("Sensitivity:", sensitivity))

```

En la matriz de confusión, las filas representan las clases reales (B para Benigno y M para Maligno), mientras que las columnas representan las clases predichas por el modelo. En este caso, se tienen los siguientes resultados:

-   Para la clase Benigno (B):

    -   Se predijeron correctamente 108 casos de la clase Benigno (verdaderos negativos).

    -   Se predijo incorrectamente 1 caso de la clase Benigno como Maligno (falso positivo).

-   Para la clase Maligno (M):

    -   Se predijeron correctamente 59 casos de la clase Maligno (verdaderos positivos).

    -   Se predijeron incorrectamente 3 casos de la clase Maligno como Benigno (falsos negativos).

-   Precisión (Accuracy): En este caso, la precisión es de 0.9766, lo que indica que el modelo tiene un alto nivel de precisión en la clasificación general.

-   Especificidad (Specificity): En este caso, la especificidad es de 0.9729, lo que indica que el modelo tiene una alta capacidad para identificar correctamente los casos Benigno.

-   Sensibilidad (Sensitivity): En este caso, la sensibilidad es de 0.9833, lo que indica que el modelo tiene una alta capacidad para identificar correctamente los casos Maligno.

## [4 Realizar de nuevo NAIVE BAYES pero con las características encontradas en el paso anterior.]{.underline}

```{r}
# Obtener los coeficientes que no son cero
non_zero_coefs <- coef(model, s = "lambda.min")
non_zero_coefs <- non_zero_coefs[, 1]  # Tomar solo la primera columna de coeficientes

# Filtrar los coeficientes que no son cero
non_zero_coefs <- non_zero_coefs[non_zero_coefs != 0]

# Imprimir los coeficientes que no son cero
print("Coeficientes no cero:")
print(non_zero_coefs)

```

[**1. Del paso anterior obtener los coeficientes que no son cero**]{.underline}

```{r}
# Obtener los coeficientes que no son cero
non_zero_coefs <- coef(model$finalModel, s = model$bestTune$.lambda)
non_zero_coefs <- non_zero_coefs[-1, ]  # Excluir el intercepto

# Convertir a matriz densa
non_zero_coefs_dense <- as.matrix(non_zero_coefs)

# Filtrar los coeficientes que no son cero
non_zero_coefs_filtered <- non_zero_coefs_dense[non_zero_coefs_dense != 0]

# Imprimir los coeficientes que no son cero
print("Coeficientes no cero:")
print(non_zero_coefs_filtered)



```

[**2. De dichos coeficientes realizar el algoritmo de Naive Bayes**]{.underline}

[**3. ¿Ha mejorado la clasificación respecto al paso 2 ?**]{.underline}

[**1. ¿Por qué ?**]{.underline}

[**2. ¿Es mejor o peor la regresión logística de lasso ?**]{.underline}

[**3. Sin hacer KNN, por qué tendríamos un peor rendimiento ?**]{.underline}
